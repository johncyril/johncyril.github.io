---
layout: post
title: "Bit by bit..."
date: 2010-04-05 16:49
author: admin
comments: true
categories: [Technology]
tags: [32, 64, 64-bit, binary, bit, Bit by bit, multi-task, processor]
---
<span style="text-decoration: line-through;">A </span><span style="text-decoration: line-through;">short</span> one for the non-techs.

If you've read myÂ  "<a href="http://www.google.co.uk/#hl=en&amp;source=hp&amp;q=hardware+lowdown&amp;meta=&amp;aq=f&amp;aqi=&amp;aql=&amp;oq=&amp;gs_rfai=&amp;fp=459b761b84e2996a" target="_blank">hardware lowdown</a>" posts previous to this, what's next should follow up nicely.

"<a href="http://blog.johncyril.com/?p=91" target="_blank">The processor</a> in your computer does all the "thinking", "talking" and "fetching" of information.."

Well, that's wonderful - but what information?

Meet the bit. And there are two types; type 0 and type 1.
<!--more-->And that's it. Really. All information is basically a load of 0s and 1s. Computers work in binary.
While us humans count in base 10, computers count in base 2.

Human: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 (and here we enter the "tens" column)
You could also think of base 10 (human) counting as this 0001, 0002, 0003, ..&lt;Skip a few&gt;.., 0010, 0011, &lt;skip a few&gt; , 0026... You get the idea... My point is all these numbers can be *preceded* by any number of 0's - it doesn't change the meaning...

In contrast a computer will do this:
0, 1, 10, 11, 100, 101, 110... The behaviour you see after the number 1 is the same as what you'd see after the base 10 (human) counting of 9.
Now in mathematical theory, preceding these combinations with 0's doesn't alter the meaning or value of the numbers. In computing however, it makes all the difference..

Computers as I've said before are very, *very* stupid. They can only in essence do little more than count. It's this basic counting operation performed in imaginative and multiple ways that allows us to actually do useful stuff...

So what's my point about the preceding 0's?Â  Well computers don't have a limitless amount of memory. While it's <a href="http://johncyril.com/?p=75" target="_blank">steadily increasing</a>, it's not unlimited. As a result, there are limits to the length of numbers computers can count or the largest numbers they can deal with (don't forget about negative numbers too!).

The unit size of a bit is one. A combination of 8 0's or 1's, is frequently referred to as a "byte" - familiar word? You may also have heard "kil0-byte", "mega-byte" and "giga-byte" ... 1 000, 1 000 000 and 1 000 000 000 bytes respectively - thats 8 000, 8 0000 000 and 8 000 000 000 *bits**.***

Anyway, these bytes are the most common grouping of bits and can be thought of as words of a set length.
If our English alphabet was only made up of the characters a,b and every word had to be 8 characters long, how many different combinations could you make?
Replace a with 0, b with 1 and you've now got a common computer language. In fact our own english alphabet has been translated into this kind of binary..

The letter "H" in it's byte-length binary form is: 01001000

While "Have a nice day" looks something like this: 01001000 01100001 01110110 01100101 00100000 01100001 00100000 01101110 01101001 01100011 01100101 00100000 01100100 01100001 01111001

It turns out that the number 8, is actually quite small. Over the last decade and a bit (ha ha), 32-bit <a href="http://blog.johncyril.com/?p=9" target="_blank">operating systems</a> and 32-bit processors have been the norm. This means that your system can handle 32 bits at any one time.
Of late, PC makers and people are beginning to *really* come round to 64 bit technology. And it's not new. In fact it's been around you for ages! Ever wondered what the "64" in Nintendo64 stood for? Yup! And PS2 had the same...

Only in the mid-2000's did it start making its way under people's desks. A big reason for this was <a href="http://blog.johncyril.com/?p=36" target="_blank">Apple</a> and their full implementation. Apple stuff was so much faster and one of the big reasons was the double bit length in processing.

The second gain is RAM and the amount that can be "addressed" (talked about)  at any one time.
32-bit processing can addressÂ  a maximum of (just under) 4 giga-bytes of  RAM, while 64 can address potentially 16 thousand...

In other words, it makes your computer a more efficient female. Multi-tasking. Think of 64-bit as a 26-year old beauty with 2 kids, diary in one hand, baby in the other, dinner on the stove, chatting to her husband on speakerphone and thinking of the feminist, flag-waving protest penciled in next sunday.

In comparison, consider 32 bit as an ailing fatty. Fish fingers in the frier with the inability to talk and watch yesterday's episode of doctors at the same time - let alone smell something burning....

Got the picture?
